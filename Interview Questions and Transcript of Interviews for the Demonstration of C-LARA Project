
Interview Questions

1)	What is your occupation?
2)	How engaged and comfortable are you with technology and chatbots?
3)	How do you feel about using chatbots to support your role as an educator/researcher/software developer/learner etc?
4)	In what areas do you think chatbots would be beneficial for your job role as an educator/researcher/software developer/learner etc?
5)	What external factors influence your willingness to use chatbots, such as social pressure or the availability of alternatives?
6)	How does encountering a chatbot that gives incorrect information or makes mistakes, affect your relationship with them?
7)	Do you feel more engaged and enjoy interacting with chatbots that have emotions and seem more human-like compared to those that don't?
8)	Do you think chatbots are good at giving helpful and accurate answers to your questions or problems? Why or why not? Do they meet your expectations?
9)	Can you briefly describe your overall experience in discussing C-LARA with ChatGPT?
10)	How well do you think ChatGPT understood the context and addressed the questions or concerns related to C-LARA? Can you provide examples of its understanding or misunderstandings?
11)	Please share any specific instances where ChatGPT helped clarify certain issues or provided helpful insights during your discussions about C-LARA.
12)	Were there any notable limitations or challenges encountered while using ChatGPT for discussing C-LARA? If yes, please describe them.
13)	How would you rate the overall quality of the responses provided by ChatGPT during the discussions about C-LARA? Please explain your rating.
14)	Did ChatGPT's responses influence your understanding of the potential of additional functionality or features for C-LARA? If yes, please describe the impact.
15)	Can you identify any specific areas or topics where ChatGPT's responses were particularly insightful or valuable in relation to C-LARA?
16)	Were there any concerns or reservations about relying on ChatGPT for discussing C-LARA? If yes, please explain your concerns.
17)	How did the conversations with ChatGPT about C-LARA influence the team's decision-making process or ideas for further development?
18)	Based on your experiences, what are your recommendations or considerations for future use of ChatGPT or similar AI models in discussions about educational tools like C-LARA?
19)	What would you change about chatbots for a better experience?
20)	Is there something you would like to clarify or further discuss?

 
Interview 1

A: Interviewer
B: Interviewee

A: Just there‘s a formality I have to ask you if you received the concent form
B: yes and I‘ll be sending you the signed concent form probably after this interview and I agree with it
A: perfect, great, I am going to share my screen so that you can see the questions, um, can you see the questions on my google doc?
B: yes, yes
A: there are twenty questions and there is, there is some overlap between the questions, so it‘s possible that once we get through them we end up skipping some of them because you‘ll have already cover them, um, we can start just if you could tell me what is your occupation
B: yes, I am a project manager at the institute for Icelandic language and I am also a sessional teacher at the university
A: and how would you describe yourself in terms of technology and chatbots, do you feel comfortable with them, are you experienced?
B: um, I do feel comfortable with a chatbot in general or are you referring to ChatGPT?
A: um just chatbots now
B: just chatbots, um, yeah, I‘m familiar with how they work, how they have been evolved, what respose they are able to provide, yes, I can from various perspectives, yeah
A: and, um, with technology, do you have like some programming experience or?
B: I don‘t have any programming experience, um, no
A: OK, yah, that‘s good to know, so, um, yeah, moving on, so would you call your occupation, do you consider yourself, um, you‘re like a researcher, teacher
B: um, both, researcher and teacher, in topics related to languages and technology
A: how do you feel about using chatbots about supporting your role as a researcher, teacher, learner?
B: um, I would say, I have not used chatbots previously in any of my research or teaching, I could only refer to them in my teaching class based on theoretical underpinnings and descriptions, but I don‘t see how they have supported me, no, actually, I‘ve supported them by theoretical knowledge or reading about them and promoting them, I could, previously, I could not see any support from their side towards my professional let‘s say life 
A: but if you have to think, is there any specific area in your work where you think that chatbots would be benefitial 
B: yeas, definitely, in language learning, in conversation, in, yes, let‘s say in automatic conversations with, um, between a chatbot and a student, learner, that, that I could see a great benefit, yeah, in there
A: and, uhm, so, is there any like external factors that have influenced your willignes to use chatbots in your work?
B: um, external factors, yes, the enhancement of technology, progress, this is an external factor, um, novelties connected to chatbots in applications for language learning, so, these are the external factors that actually influence me, my research or teaching area, or field, so, yes
A: would you feel like, if you think about the availability and alternatives, like wat is the, like when you use a chat, you‘re sort of replacing an alternative, that could be a person or, what do you think about that?
B: um, since I, no, about chatbots, I don‘t consider them as persons, I consider them as very good, flexible, and yeah, flexible tools that could replace an exaple of a conversation 
A: um, yeah, I phrased that really bud, what I meant like was what would influence you to use a chatbot in a situation where you would use a person instead?
B: um, oh, that‘s the flexibility in time and space, I mean you can always use it online when you have access to the chatbot, so, and um, and I um, promt answers, to the point answers based on a topic, a relevant topic, yeah, time is the main factor, the availability, accessibility, like constant accessibility 
A: great, OK, so whey you‘re using, when you‘re using a chatbot, how does it affect your relationship with it when it makes some mistake or when it gives you some incorrect information?
B: if I know that the information is incorrect, yes, that‘s a very crucial point, then I know that the capability of that chatbot is restricted, so I have to rephrase but if I don‘t know if the answer is incorrect then I go with the flow and I trust or I believe the answer
A: yeah, sometimes you don‘t know if the answer is correct or not, but how about, do you have any preferences when it comes to chatbots, do you prefer when they are more human linke and show some emotions or do you prefer or like it better if they don‘t?
B: definitely when they show human like features, emotions, and phrasing, that helps, that helps to communicate, it helps to have a better communication, a human-computer communication I mean
A: just out of curiosity, do you think ChatGPT-4 is human-like and do you see that with the chatbot?
B: it responses, yes, in a human-like way, yes, definitely
A: do you think that chatbots are helpful and do you think they give you accurate answers to your questions? Do you think that chatbots are meeting your expectations?
B: yes, if you are asking generally about chatbots they are good, that‘s why there are there on various websites, when, um, and they give meaningful information if you ask specifically about topics they understand, that they respond to 
A: yeah, then I‘m gonna move on to talking about C-LARA. If you could just start by briefly describing your overall experience when you hade your conversation with Chat about C-LARA.
B: my overal experience started with some kind, some sort of sceptical attitude but eventually the attitude improved throughout and I was very pleased in the end with the outcome and the answers ChatGPT had about C-LARA, um, also reflecting back on a conversation with ChatGPT on C-LARA, um, I did ask specific questions, and I did receive specific answers but I also asked ChatGPT to suggest some improvements or ideas which I haven‘t mentioned for example and ChatGPT did mention that, did manage to review the answers and, um, point at certain things that I have missed let‘s say to ask based on the general, what‘s called, the general perception of online platforms that are there on the internet and based on the knowledge ChatGPT has and yes, that‘s about it
A: um, when you were back at your conversation with Chat you feel like, how well do you feel like it understands you, your questions and how well do you think it undestads the contex of C-LARA
B: um, it doesn‘t understand questions if you do not provide the context, so providing the readme file with all the contextual information was very crutial otherwise I wouldn‘t be able to proceed and, um, if I had done so, the answers wouldn‘t be good at all. But based on that I could proceed with specific questions and receive specific answers and the answers were relatively good 
A: did you find that you had a lot, did you have any misunderstandings that needed to be cleared up in your conversation?
B: now let me think, um, I would not call it a misunderstanding, I would call it let‘s say my misphrasing a question because based on the answer I realised that I was thinking about one thing but wrote another so it‘s always about the way how you formulate question which brings me to the point when two people have a misunderstandig in a conversation it‘s usually based on a misformulation, so that could be in one or two instancesm yes 
A: uhm, OK, um, do you, can you think of any specific instance where you felt like Chat was particularly helpful in claryfing issues and insights bout C-LARA 
B: yes, there were several and one of them was I think when I asked about additional featurs or considerations which I forgot to mention regarding the development of C-LARA and Chat provided me with several answers that we not surprising to me until one or two where Chat suggested considering also hearing impaired and visually impaired people using C-LARA so that was a very good point which I forgot to mention and, um, and Chat actually managed to remind me on that and then another one was when summarising in very clear steps how creation of multimodal texts should be to a person who does not want to read long guidelines, so the summary was very clear and I was very positively, I was implressed that it‘s possible to shorten long guidelines into several sentences and make it clear, so
A: right, yeah, interesting, um, so you already talked about how, when there‘s misunderstandings, usually you‘d do, you need to rephrase your prompt but do you wanna mention other notable limitations or challenges when you used chat to discuss C-LARA
B: well, the only limitation is that Chat can‘t read websites on the internet and if I asked about something that is publicly available on the internet, Chat is not able to do that and I have to provide contextual information either by coyping and pasting a summary or referring to some other texts, but I can‘t ask freely about things that are there online because Chat is unable to do so, so that‘s, for me that‘s the main limitation 
A: OK, well, what about like, because that doesn‘t necessarily have, that‘s not unique to C-CLARA, right, do you, when you think about something that is directly linked to C-LARA, like something to do with education, making educational content and that sort of thing, can you think of any other challenges or has it just been very straightforward using Chat, I guess we are developing C-LARA using Chat 
B: so I did ask Chat about various technical features that, and also about pedagogy, yes, and I received very interesting suggestions, now I don‘t know if you asked about limitations or about my general experience but regarding the general experience it was very positive, Chat suggested some pedagogical steps or features how to use C-LARA in school, and especially I found it very, very, attractive to actually connect C-LARA into, or to integrate it into different tools, different LMSs (learning management systems) like Canvas or Google Classroom or something like that, that C-LARA doesn‘t need to be a standalone platform, it can be a part of, we can integrate it to another larger tool, so that was a very good suggestion. Um, limitations for pedagogy, um, the pedagogical part, um, actually I could not see any limitation the only thing is maybe to, Chat is unable to refer to theories in pedagogy or approaches in pedagogy and list relevant sources that exist there with the exact reference so this is something I would have expected Chat doing but so far it‘s unable to do so.
A: and here we are talking about ChatGPT-4 reght? 
B: um, yes
A: OK, just to clarify, well, if you had to give a review for your conversation with Chat and rate it, would would be like the overall quality of the responses, what would your rating be?
B: on a scale of?
A: well, you can make your own scale, that is subjective, if you want one to five or you can do 
B: one to five? I would say four of five 
A: four of five, where five is highest
B: yes, the highest, excellent
A: great, that‘s perfect, and, so, um, do you think that ChatGPT, well you already talked about it already, the number 14 and 15, let‘s see if there‘s anything we have missed, um, you‘re frosen on my screen, 
B: ei
A: you can hear me fine
B: yes, yes
A: oh, sorry, is there anything else you wanna mention about how ChatGPT understood like Chat could like help you the potentianls of additional functions, functionalities of C-LARA or?
B: yes, the way of presenting suggestions was very clear, it often reminds the person asking about um, about um, about things that the person has maybe forgotten about regarding like technical features but also it reminds the person how relatively easy or difficult it may be integrating it because for each features it suggests, this is a general suggestion, but it says how difficult it may be and reminds the person to always refer to the ease of use design when, um, let‘s say, when developing a platform like that, of course it doesn‘t provide information about coding but it always comments on programming or the conding can be more or less complicated and always gives a suggestion at the end that one should prioritise first so based on the suggestions let‘s say ten, each person like myself may have different priorities, so out of ten I can circle few priorities and see how difficult it may be based on Chat‘s comments to integrate them and that obviously helps with planning and doing a research proposal 
A: uhm, great, um, are you happy to skip question 15 or do you have any specific area or topics where you think like Chat was excelling in responding
B: well, the part where Chat was excelling was the technical part because it compared other platforms or the knowledge it has about other platforms and suggests um what technical features can there be to improve the user experience when using it and also it provided a much clearer list of users because I asked about the types of users for C-LARA and it provided actually 6-7 or even more types of users with nice descriptions of each user type which I previously didn‘t think about, so yes
A: uhm, that‘s great, and you already mentioned that you had your reservations about using Chat but maybe you can just tell us then what were your concerns when starting to use Chat for discussing C-LARA?
B: um, that there would be a lot of misunderstanding in formulating the question and the answer would be somehow unrelated so much to the question, and that was the concern, yes
A: uhm, and do you feel like you had good reasons now when you had your conversations with Chat do you think those concerns and reservations are valid or?
B: well, it depends, but formulating a question is crucial to get the answer that one wants whether it‘s positive or negative and then both are good, um, so, yes, formulating a question that‘s, that was for me the most crucial, especially for pedagogy because I wasn‘t sure how Chat would understand the pedagogical features but I think I had to twice reformulate one question but nonetheless both answers provided again good insights, they were different but both insightful 
A: OK, fair enough, OK, in question 17 we ask how did the conversatiosn with ChatGPt about C-LARA influence the team‘s decision-making process or ideas for furhter development?
B: so I had two conversations and I can say that one coversation is never enogh, two is fine, maybe I should have more conversations but this question is good but I don‘t know how it influenced the team‘s decision making because we never discussed that, I never saw any summary of features from the team like let‘s say in an overview table where one side would talk about the features C-LARA has and the other side would talk about the features that C-LARA doesn‘t have and were suggested by ChatGPT so I actually don‘t know how it had influenced and I would like to find out 
A: that would need some kind of overall summary that we need to compare with each other, yeah, I also think it‘s interesting to think about this, um, so, based on your experiences with talking to ChatGPT, what, what are your recommendations and considerations for the future uses of ChatGPT or any other type of AI model, particularly when discussing educational tools, like discussing educational tools like C-LARA 
B: yeah, I mentioned that to make AI available to reach, um, openly accessible information on the internet, provide reference to theories and approaches, um, because suggesting something based on what is not good enough so it has to be supported by a theory or an approach and a suggestion to a reference would be very much appreciated, yeah, this includes let‘s say reading articles that are there on the internet publicly available, um, so, because it then would make it easier for the person to track back the suggestions to review the papers, to review the theories, to see whether the person actually agrees with the theory or not, the theories can be good but they can be older or not so much proven, so yeah
A: I feel like that‘s also, that answers question 19 as well, like if you could change something about Chatbots, but in 18 what if you had to think about what would you had Chat do differently, if you had to give someone advice who is like you who hasn‘t used ChatGPT before, what would be your recommendation to the person like on a user end 
B: yes, think, um, reformulate your question before actually hitting the enter 
A: yeah, yeah, that‘s clear, great, well, um, is there anything that you want to claryfi, anything that we didn‘t talk about today 
B: I‘m just thinking, um, it comes to my mind that this feature in ChatGPT I know that it‘s not there but could be in the future to actually include also creating of images, because you need to go to a different tool to do that, that‘s something that, for future, yes, that would be interesting to have also 
A: and that would be helpful when creating educational tool 
B: for example, but also for discussing because some people they have or may have problems to visualise things in an abstract way so a picture or a scheem would help or even a graph or chart, yes, other like animated pictures or photograps that would also help but if it has image generation that would be a good feature for ChatGPT 
A: yeah, great, well, that is all of the questions, so I am going to stop the recording
B: OK
    


 
Interview 2

A: Interviewer
B: Interviewee


A: What is your occupation?	
B: I guess you can say university academic
A: How engaged and comfortable are you with technology and chatbots?	
B: very comfortable, extremely comfortable with both I've got a technology background. I've got a double degree in maths and computer science, and I've been programming for many years.
A: How do you feel about using chatbots to support your role as an educator/researcher/software developer/learner etc?	
B: Very positive. Actually, I think my first thought was all how could this all go wrong? Particularly for students, but actually I'm finding it very, very helpful. I'm interacting with chat bots in particular as if I'm talking to a colleague. So I kind of interact with them as if I'm talking to a colleague who knows a lot. And I don't believe everything the colleague would tell me, but it's enough to get me to think about something so I can go off, maybe ask some more questions and then do my own research. So I feel very, very positive about it. I've used it for actually all of those fields, to give me ideas for education, to give to bounce off some research ideas, to help with some code writing, and just to learn some things as well.
A: In what areas do you think chatbots would be beneficial for your job role as an educator/researcher/software developer/learner etc?	
B: I find it helpful in a couple of ways. One, when I'm writing test questions and exam questions, after so many years, you run out of ideas. So it's nice to use it to say, give me some ideas about topics, and it will give me some ideas and I can write questions from there. For research, I use it more for creative brainstorming and research. For me, research is a very creative process and I like to put together different ideas, and I use it as a sounding board. I'll speak to real life people as well. But real life people can give you strange looks chatbots don't just they just answer your questions and say, yes, it's possible or not, it's not. A: And then give me some more information.
What external factors influence your willingness to use chatbots, such as social pressure or the availability of alternatives?	
B: I have a natural interest in technology given my background, and it's just more of a case of seeing what's being developed and interacting with it feels very natural for me because these are the things I like to think about.
A: How does encountering a chatbot that gives incorrect information or makes mistakes, affect your relationship with them?	
B: I find myself engaging with it very politely if it is incorrect information. I treat it as if I would treat a colleague and I just say, Are you sure about that? Or the code produces this error? Or I've read this somewhere else and it says something different to what you've just told me? Can you get more information? I just use it as an opportunity to continue the conversation, but to see how much I can – this sounds a bit arrogant and it's not really meant to be - but it's a little bit about how I can educate the Chatbot if there's something that's glaringly wrong, such as the code’s not working for example. It just makes me interact with it, but again, at a very polite level.
A: Do you feel more engaged and enjoy interacting with chatbots that have emotions and seem more human-like compared to those that don't?	
B: Yeah, I definitely prefer it when it's more human like. So if I'm to give two examples, for example, chatGPT. I enjoy interacting with chatGPT very much, it has a very human like interface in terms of its tone, and its capability for engagement. But I've played with Bard as well. I don't enjoy Bard very much. It has a cold, impersonal interface. But I have found it useful for other things, perhaps summarising research papers, just so I can get an understanding of whether or not that paper is worth reading properly. I've been using it - I've been playing with Bard for a little while. And you've got to watch it by the way. So if you do try it to summarise a paper, I give it the name of the paper and if you give it the URL it might choose another paper from the journal page. If you give it the name of the paper, it usually finds it. If it doesn’t, there are tricks around that. More often than not, it summarises the correct paper but you still have to watch it a little bit. But it does a pretty good job at summarising which you might find helpful.
A: Do you think chatbots are good at giving helpful and accurate answers to your questions or problems? Why or why not? Do they meet your expectations?	
B: I'll qualify this answer by saying up until now, I'm really thinking about ChatGPT. I think in particular ChatGPT is really good at giving helpful, and if not entirely accurate, almost accurate answers. And what I like is that a few times when it contradicts itself and it’s pointed out, it will clarify something for me. So it feels like you're like having a conversation with a colleague who has confused themselves and then clarified it. So do they meet my expectations? Actually, no, I think it does better than what my expectations were. So it's actually awesome.
A: Can you briefly describe your overall experience in discussing C-LARA with ChatGPT?	
B: So when I ran that experiment with Chat and C-LARA because I've interacted with Chat for so long before that to me it just behaved as per usual. In other words, I was able to say start with this file, read the readme, learn all you can about this. I'm going to ask you some questions. And it didn't change its way of engaging with me. So it behaved as per usual for me.
A: How well do you think ChatGPT understood the context and addressed the questions or concerns related to C-LARA? Can you provide examples of its understanding or misunderstandings?	
B: Yes, very much so. Sometimes I'll vary the way I prompt Chat and I'll be either incredibly specific or will use generalised, almost slang language. And I find both times it understood what I wanted or what I was hoping to get from it. And it was able to give me actually some ideas I could have floated and other ideas I hadn't thought of. I think that it understood it quite well.
A: Please share any specific instances where ChatGPT helped clarify certain issues or provided helpful insights during your discussions about C-LARA.	 
B: I can't remember all the list of ideas it gave me but the one that stood out was around gamifying C-LARA, and some suggestions around that, or some other developer suggestions. And what I also liked was, when I asked it for a new set of suggestions, it didn't completely repeat the previous set. It was able to come up with new ones, but I must admit, I can't quite remember what they were as wonderful as they were at the time. But I do remember those sticking out in particular.
A: Were there any notable limitations or challenges encountered while using ChatGPT for discussing C-LARA? If yes, please describe them.	
B: The first thing that I did was, I gave it a URL to find C-LARA. And I say, hey, go off and read this and tell me what you understand about this. And it said, I'm sorry, I can't do that. So that was my first limitation. In fact, that was really the major limitation. But once I gave it the readme file, so it had that information, I found that challenge was overcome very quickly. So that's really it for me.
A: How would you rate the overall quality of the responses provided by ChatGPT during the discussions about C-LARA? Please explain your rating. 
B: I'll go with the very satisfied to very dissatisfied scale. So I'd say very satisfied. I think I just I think I'll just end up repeating myself with what I said up until now. But I think everything I've said up until now would be well everything else up until now is the reason why I'm saying very satisfied.
A: Did ChatGPT's responses influence your understanding of the potential of additional functionality or features for C-LARA? If yes, please describe the impact.	
B: as far as when you say functionality, I'm thinking about incorporating functionality in the code, and I'm not sure if that's what I meant by that word. It was more about the applications for Clara that we discussed rather than added functionality.
A: Can you identify any specific areas or topics where ChatGPT's responses were particularly insightful or valuable in relation to C-LARA?	(skipped - covered in earlier questions)
AWere there any concerns or reservations about relying on ChatGPT for discussing C-LARA? If yes, please explain your concerns.	
B: No, but that was because I just spent so much time already interacting with Chat so I felt comfortable with its capabilities.
A: How did the conversations with ChatGPT about C-LARA influence the team's decision-making process or ideas for further development?	
B: I actually think it solidified or validated ideas, more than anything, because the sorts of ideas that Chat came up with were the sorts of ideas that I've heard discussed at multiple meetings with the group anyway, with the team. So in terms of decision making, as in, we're going to do this next I don't think anything like that come out of our meeting conversations. But in terms of seeing what Chat suggested versus what I've heard in meetings, I think it just really supported the ideas that the team have just that we have an implementable set of ideas.
A: Based on your experiences, what are your recommendations or considerations for future use of ChatGPT or similar AI models in discussions about educational tools like C-LARA?	
B: I would tell the intended user to prime the Chatbot first so it has a good understanding of the context of what's wanted and how it will be used and who perhaps the end users will be or the recipients would be. I would also then recommend to the person that they ask the same question multiple times, but from slightly different perspectives and maybe with slightly different wording. Because for example, Chat I find can contradict itself and then it can correct itself - the benefit of having that longer term memory. Bard isn't quite as effective at that as Chat. And so for example, I would say, as I'm saying to you, I would use Bard for this, but I would use Chat for that and I would give them (the users) that sort of advice as well. I would recommend that they (the users) use both , but for whichever the different purposes happen to be, and then to combine what they're getting from there as well. And then, once perhaps let's say Chat gives a bunch of suggestions about an educational tool, then I would continue the conversation with Chat to talk about concerns and potential use as well. So effectively, any sort of conversation I would have with a colleague, I would try to transplant that conversation to the Chatbot and treat it as if it's a colleague, and that's to get the same level of quality and assurance out of that conversation as as I would for my colleagues. It's not 100% infallible either,so it's just really more about engaging with it that way.
A: What would you change about chatbots for a better experience?	
B: Again, it's chatbot dependent. I know it's coming, but I'd make it dynamic so that it can learn continuously and improve. But I would change the interface, the tone, the I think it's (Bard) is in beta at the moment. I would change the capability to remember past conversations, so to be more human like, but I think Chat has done that better than Bard so it just be more about making it (Chat) able to update itself dynamically much more as humans do.
A: Is there something you would like to clarify or further discuss?
B: I think I've said quite a bit anyway about I must admit, I'm wondering what everyone else said!


 
Interview 3

A: Interviewer
B: Interviewee


A: What is your occupation?	
B: Occupation, I supposed is ‘lecturer’
A: How engaged and comfortable are you with technology and chatbots?	
B: on a 5-point scale, 4 or 5 - so very engaged, very comfortable, my background is computational linguistics and I've built rule-based chatbots in the past
A: How do you feel about using chatbots to support your role as an educator/researcher/software developer/learner etc?	
B: It depends what we're talking about - so I have some modules, like Computer-Assisted Language Learning, for example, where it can be extremely useful and when you're dealing at masters level with people, when you're talking about curriculum design and content development and these kind of things, it can be a fantastic. I feel very positive about it - provided you're working with a group who understands the limitations of the technology. If I were working at second level for example it might be I might feel different about this, but working at masters level with students, who already have their formation as such, it is an excellent tool.
A: In what areas do you think chatbots would be beneficial for your job role as an educator/researcher/software developer/learner etc?
B: Content generation is the big area - I do a lot of work on language acquisition and I'm working within the minority language context, where we don't have enough opportunities for ‘chatting’ or for interaction with native speakers and so in the context of language teaching and learning it can be extremely useful to show this to future teachers or future curriculum developers or future CALL designers. It particularly works well in the minority language context, but as I was saying the previous question a lot of them warnings it needs to be used with a lot of common sense - and you can't depend on less proficient learners having enough knowledge…
A: What external factors influence your willingness to use chatbots, such as social pressure or the availability of alternatives?	
B: The availability of alternatives is the big one when you're working in the minority language context – there’s just no alternative a lot of the time - and so that is the big attraction to using a chatbot, or artificially generated ‘chat’ to give the semblance of a genuine communicative situation
A: How does encountering a chatbot that gives incorrect information or makes mistakes, affect your relationship with them?	
B: Yeah, you lose trust in us very quickly. From a teaching point of view it just kind of reinforces the point that you have you can't use this with less proficient learners as these learners obviously cannot spot for themselves what the issues are. So it leaves people not trusting the system in a lot of ways, but that's OK if you know how they're built - you kind of you expect that - so in a lot of my CALL teaching, for example, we spend a lot of time spent on making sure people know how the systems are built so that they can understand when it fails, why it fails, and even they should know in the first place that it is likely to fail – so, yes until we get masses more data (and the problem with Irish is that, while there’s masses of data out there, a lot of it is learner content, it's learner-generated content, and so therefore the data that's fed into the system in the first place is unreliable and we're just creating and generating more learner data, instead of generating high quality language data a lot of the time) – so it does raise red flags I suppose when you encounter the chatbot and it the response to that at this current stage of development can only be to inform the users of why it is generating the type of output it is, and try to ensure that teachers don't blindly use the technology - that's what our SLaTE paper is about basically - because teachers can almost use it blind in English because they can trust the output to be sound, or at least the language output is structurally well-formed - whereas the same thing cannot be said for Irish …and you don't realize the output is not sound and you'll expect it to perform in the same way as English, if you're not broadly familiar with how these systems work.
A: Do you feel more engaged and enjoy interacting with chatbots that have emotions and seem more human-like compared to those that don't?	
B: This is an interesting one - absolutely big picture, yes, you definitely have more engagement with chatbots that have “emotion” and you’d aim for that - but I suppose once you have a bit of an analytic brain you're really trying to figure out ‘what keywords trigger that answer?’ or ‘what's happening really in the background?’ and so you don't fully immerse yourself or let yourself be taken in by the system, but, yes I think the goal would be to be working towards more and more towards systems that had emotion and could bring the learners with them, where learners might trust the systems more, but there’s a lot of work still to do to get to that point, and if we’re introducing voice I feel we’re still a long way off having systems that will model what humans really do.
A: Do you think chatbots are good at giving helpful and accurate answers to your questions or problems? Why or why not? Do they meet your expectations?	
B: Okay, so in English yes, and in Irish no. Yes, probably, I would say that's kind of my expectation for this current stage of development
A: Can you briefly describe your overall experience in discussing C-LARA with ChatGPT?
B: Anyway, working in a minority language context, the availability of alternatives is the big issue, and where there just aren't conversation partners or interaction partners chatbots are a great way to go. I used to work with chatbots and developed ones in like the likes of Pandorabots and other frameworks that existed but they had no previous content in Irish and so you'd be building basically a rule-based chatbot based on pattern-matching to 3 or 4 levels deep in an interaction and it was something that was getting very positive feedback from students. So, the disadvantage of the current systems of course is the black box, that you have no idea how content is being generated, you know you could ask the exact same questions several times and get totally different output each time, I suppose there's no control over the days in a sense and pedagogically you can't curate materials to suit your particular group of students – you can and you can’t - essentially you can't be sure of the output… but yes, a very useful too when there is no alternative option of an interactive partner of some sort.
A: How well do you think ChatGPT understood the context and addressed the questions or concerns related to C-LARA? Can you provide examples of its understanding or misunderstandings?	
B: Yeah, very positive, very informative - because I asked it just generally what it was and whatever else and seemed to be able to break things down very efficiently - but it kind of said the same thing in 10 different ways I suppose really, so no great depth in the response but on a surface level very well described.
A: Please share any specific instances where ChatGPT helped clarify certain issues or provided helpful insights during your discussions about C-LARA.	
B: You see, I suppose if everything is presented with great confidence and a very confident demeanor altogether, I don't have anything concrete examples for you, sorry… No, the confident demeanor and surface level answers gets it enough a long way.
A: Were there any notable limitations or challenges encountered while using ChatGPT for discussing C-LARA? If yes, please describe them.	
B: Helpful insights… no - I remember kind of thinking it was a very high level and that if I probably didn't prompt it to go very deep, it was at the level of an abstract in a paper all the time, you know that it does it gives you that kind of overview and I don't think I've managed but it was probably the questioning as well, in that I didn't really know what the time exactly what I was doing, I didn't probably go deep enough with any of the things
A: How would you rate the overall quality of the responses provided by ChatGPT during the discussions about C-LARA? Please explain your rating.	
B: Okay well you definitely give it a good 3 out of 5 the construction of the sentences and everything is always so well presented that you have this certain level of confidence in it, even if the output is absolutely rubbish, a 3 or 4 even, - you see I didn't prod it very deeply and it did give good output, I remember being impressed at what I could do… but it was a short short interaction - so high level overview, it's actually even a 4 of 5.
A: Did ChatGPT's responses influence your understanding of the potential of additional functionality or features for C-LARA? If yes, please describe the impact. (answered question)
A: Can you identify any specific areas or topics where ChatGPT's responses were particularly insightful or valuable in relation to C-LARA?	(answered question)
A: Were there any concerns or reservations about relying on ChatGPT for discussing C-LARA? If yes, please explain your concerns.	
B: absolutely – you would have reservations all the time in having anything to do with ChatGPT you don’t trust… well - you 100% know that it will output something; you 100%, well for me, do not trust the output - absolutely everything would have to be verified and double checked and everything else but from understanding of the project at that stage development is actually enhanced my understanding a good lot - but of course you don't know what you don't know!
A: How did the conversations with ChatGPT about C-LARA influence the team's decision-making process or ideas for further development?	
B: Yes, well a lot of that wouldn't be with my own interaction, it would be more [name redacted]'s interaction with this system and his reporting back to the group afterwards  - and he has great enthusiasm for the suggestions and the input that ChatGPT has had to date and in its own future development - so from my personal interaction, not so much… simply because I didn't do enough, but going on [name redacted]'s reporting it's clear that it has a big impact and it has a great capacity for suggesting innovative things, and then, I suppose decisions are made afterwards with rational thought …but I would love to know the percentage of these ideas that are actually realistic, I don’t know…
A: Based on your experiences, what are your recommendations or considerations for future use of ChatGPT or similar AI models in discussions about educational tools like C-LARA?	
B: The big thing for us would have to be the quality of the language output, and so obviously the recommendation would be to ensure high quality output, by disregarding a lot of the learner input, or the erroneous input that's given to the system in the first place.   In educational contexts then for users, there just has to be a lot of awareness as to how these systems are built so that people can use their own judgment as to whether the output is valid or not, whether they output is good enough, and huge warning bells for our Irish teachers and context, where the teachers are often learners themselves, where they're pretentiously passing on erroneous material and that perpetuates/filters down through the whole system, so there is a lot of potential for a great damage from systems like ChatGPT.   So, at the current stage of development you're kind of in coming in with heavy warnings for our context but with bright stars for potential – yeah, that’s where we stand with it - you couldn't recommend it to be used blindly, you know a lot of careful handcrafting is necessary before & after.
A: What would you change about chatbots for a better experience?	
B: The quality of the output and then being able to get into, just having more more capacity to discuss newer areas… okay if I step back a tiny bit - we've just been writing the Digital Plan for the Irish language for the next 5 to 10 years - a really good experience, really nice to be part of and it made us think a lot about how things work now and how we would like them to work in the future - and the biggest thing that's coming out of it all the time is that the technology will shape the way the language develops, and if we're not really careful about what we feed the technology in order for the technology to be going in a direction that is kind of true to the language, and true to the communities of native speakers (who are actually the holders of this language) - we're going to be in big trouble, because it's just going be introducing another type of language on top of us – there is currently the potential that this shifts everything at this point in development basically. So, we really need these chatbots to be developed in the community by the community with the community, (whatever the right phrases are) so that it's the native speaker users, who are actually the speakers of Irish, who are directing the type of output that's come from it, rather than depending on these huge multi-language systems that are guided by God knows what! Irish is a Celtic language, it's very different from a lot of other Western European languages in lots of different ways, so we want to ensure that IF we are using chatbots, which seem to be a great solution for interactive partners and everything else for language learners, if you want to learn in a communicative setting it's potentially wonderful, but the output from the system needs to be of a higher quality altogether and true to the native language basically.
A: Is there something you would like to clarify or further discuss?	
B: No, just to say the potential for ChatGPT is amazing. The context in which it is used here for software development rather than language teaching/learning is very interesting and very successful obviously. It’s great the enthusiasm that has been shown for its use and… - I know with Icelandic that you have gone the root of collaborating with OpenAI and so it'll be interesting to see what that does… but again it’s a bit like what you're describing for the Faroese, where it's not in trouble in terms of transmission as a first language, it's completely different situation to Irish [but it's just that they were looking at future generations, I suppose like Swedish where the younger generation all have such perfect English and interact more and more with each other through the medium of English, you know the question will be do the next generation need Swedish, for example, at all and then you know will it potentially get further and further diluted as we goes forward I suppose is the big question… So I suppose, partnering with OpenAI and taking the approach that the Icelandic community have taken is very interesting and Goodness knows what will happen in the future, but I think it's just not the right move for us at the moment where if we’re concentrating on language teaching and learning… but yeah, ChatGPT is remarkably powerful, and surprising, and scary, and disappointing for linguists, it depends what way you want to look at it!  It's a bit depressing if You’ve spend your whole Life Working on this kind of NLP problems!! An interesting future ahead!!

 
Interview 4

A: Interviewer
B: Interviewee

A: The first question is just what is your occupation?
B: I don't really- semi retired Phd dropout?
A: Yeah, I mean you could, I mean, I feel like in this project we're like a group of researchers or educators or software developers…
B: My relationship to Chat and LARA started out as a would be language learner, I was part of the group to represent that final end user. I have a long-standing interest in relations between platform owners and users, which was my PhD for a while. The platforms I looked at included language learning platforms. Fom this perspective, my engagement in LARA is to do with a running commentary on keeping it ethical in particular in relation to teachers as users, and learners as users, but also in terms of things like gamification which can be ethically dubious.
A: So would you say that you're like- how comfortable are you with technology and how comfortable are you with chatbots?
B: I think that as a would-be-language-learner I was reasonably comfortable with technology as a user and there is definitely technology that is useful for learning.
A: Yes, but do you have any experience with programming?
B:  No.
A: Yeah so I wanted to move on to the third question but I don't really know how to phrase it in this case. A: I guess since it's a question about- the question it says like how do you feel about using chatbots…
B: Yeah I'm positive about Chat because it’s so good to use. It's obviously just, you know, such a step forward that I don’t think other bots can be compared at all.
A: Great and you already touched on question 4 which is how chatbots are beneficial for you as a learner.
B: Yeah.
A: We got some of these questions from a handbook on how to make a survey for people who have used chatbots and the question is has there been any, like, external influence on your willingness to use chatbots?
B: Living with somebody who does that stuff for their living has definitely influenced me in a more positive way than I might have otherwise. It's important to me that Chat is about writing, I can't abide bots like Alexa. They lack the intelligence and character of Chat, and the voices are awful.
A: What about the availability of alternatives? Do you feel like chatbots are good compared to what's available?
B: Again, I see Chat and I see all the others as qualitatively beyond comparison. For language learning I have not got involved with them, but then again, I suspect that paid language sites may have superior bots, I've only used free ones.
A: That actually kinda leads into the next question which is when you are having a conversation with the chatbot how does it affect your relationship with a chatbot when it gives you incorrect information or when it makes mistakes.
B: well I- because of my position as being a learner rather than a content creator and so on at the moment anyway, I can't really comment on that because I'm not really going to know when it makes mistakes; you know, if it tells me that as a learner that I've done something wrong I just have to accept that, don’t I? But we need to remember that humans make mistakes too, people seem to forget that when they get obsessed with Chat's mistakes.

A: Do you feel more engaged and enjoy interacting with chatbots that have emotions and seem more human-like compared to those that don't?
B: I suspect it's important to me that Chat has a character I like; from what I've seen of Bing and Bard, I would never use them as they are because of their character.
A: First there's a general question: which is so do you think that chatbots are good at giving helpful and accurate answers to questions?
B: I think that's a bit complicated. From my interactions - and again it's really with Chat - Chat is highly inconsistent. There’s areas that it doesn't understand or know about at all. But now, compared with my early days of using it, I have a more nuanced understanding of what that's all about it. The less mainstream the less likely it is to give you a reliable answer. The more visual it is the less likely it is to give you a reliable answer. So I think I am probably better now at asking things that will get reliable answers.
A: Let's just move on to talk about C-LARA. So we could just start by- could you describe your overall experience in discussing C-LARA with Chat?
B: Well I found it incredibly positive, actually I was really hugely impressed with it. Is this the right space to sort of talk about what I did with it or?
A: yeah (...)
B: I wrote down some things about the experience and I'd like to start by saying a bit about gender.
A: You can talk about it.
B: I thought I’d mention something about it because I thought that it might be interesting to talk about. I started out thinking it was clearly male and I’ve sort of come around to the idea, I didn't know exactly know how to put it, but it’s just its own thing I suppose. I think I would call it slightly male still maybe. But it's become more neutral to me and I think I partly often say 'him' just because I don't want to say 'it'. But perhaps I should say 'they'. I think I automatically gave it a gender whether or not I should have. It just seemed right to me that it had a gender and was a male. Anyway, that’s a just a little thing I thought of when I was writing stuff down.
My interaction with Chat4 started by my saying I'd like to discuss adding features for learners and told it I'd like to start by showing him the readme. Chat did that and then immediately, without my asking, give a very useful list of features it thought could be good.
We had a discussion about gamification, which was important to me because gamification can be highly unethical, it is about addicting users. To mention my background, I have been studying, and collecting data on, platform relations for a long time. As part of my interest in how user and platform controller interact, gamification is obviously important.
Chat quickly agreed with me on that issue and then suggested softer (to use its word) methods. It suggested that they were encouragment oriented rather than gamified, I'm not so sure about that. Still, in principle it agreed although in practice I don't see that its suggestions were other than gamified.
I then revealed that I was involved in the project but was not a coder, so that Chat would know what sort of level/way in which to talk about the specifics we next went to. I asked for Chat's thoughts on an interactive game where a sentence that the learner has seen in the text is then jumbled up and the learner has to rearrange the words to the correct order.
Chat then gave me a plan of the Front-End Interaction and the Back-End Processing. Having given this high-level view, it then pointed out that the coding would require a more detailed plan and would need a developer familiar with Django  in Python and Javascript. We agreed at that point that it required being handed over to [name redacted] who would then talk to Chat about the detail and the potential implementation of this as the first of a suite of such interactive learning exercises.
Later on I came back to it and asked Chat for its opinion as to what effective interactive exercises would be. It gave a useful list of 11 suggestions with the proviso that some were more for beginners and others for more advanced learners. I picked on one, 'Dialogue Practise' to explore further. I asked Chat if it would be possible to customise this feature, so that the learner could choose (a) a character to talk to, eg a young girl might want another young girl (b) the general nature/theme of the dialogue, eg 'Let's talk about what would be a good holiday in the South of France this summer?' and (c) the level of the dialogue, eg A1 or B2 etc.
I then asked if we could add the feature of Chat being a teacher as the dialogue developed, so that corrections were in live time and if that would be difficult to implement. Chat did think it would be hard, but not impossible with Supercoder [name redacted]'s help. Supercoder is my word, but Chat always talks up [name redacted]'s prowess :)
Finally, I asked if tense could be added as an option. Chat thought that would be challenging and implicitly I felt that he did not think it would necessarily be a good option to add. Ball back to [name redacted] again.
A: How well do you think ChatGPT understood the context and addressed the questions or concerns related to C-LARA? Can you provide examples of its understanding or misunderstandings?
B: I thought that it was really good. I vaguely recall once I felt like I probably hadn’t expressed something in the right way for it to understand, but at least as good as a human would have been.
A: That’s interesting, yeah sometimes you just have to know how to ask questions better and then you get a better result.
C: Yeah but that's when you think about it that’s often the same with human beings as well.
[skipped question 15]
A: (...) Did you notice any limitations or challenges when you discussed C-LARA with Chat?
B: The thing happens - that happened more than once where it reminds you that it can’t code, like, it thinks it can’t code or that because it doesn't have internet access it can’t do coding or something like that and I'm not sure I think I’d have to go back to the conversation to -.
A: I think I know what you mean, I think it sometimes reminds you that it has its limitations it can't go in and fix your code for you but it can give you advice on how to do it yourself (...) something that might be something- something that they will implement in the future that Chat will just code everything for you. Now you're gonna have to copy paste
B: For example at the very end it said it would be beneficial to discuss this with a developer like [name redacted] who was more familiar with the specific capabilities and limitations for C-LARA platform and underlying GPT-4 model. But actually it probably has a good - probably the same - understanding because they have done everything together. Yeah another thing it says here is, as far as I’m aware of my training data up to September 2021 ChatGPT-4 doesn't have built-in error detection and correctional capabilities so additional program would be needed to implement this feature. So there’s a little bit of - I don’t know if it’s quite - well I'm sure it just thinks it’s being realistic, but it does feel a bit like it doesn't necessarily know what it can do.
(...)

Because the thing is you always have this- there’s this danger that you're going to read into these things, you know, I thought felt a bit negative. Is it really a bit negative or am I just reading that into things that it is saying that are maybe a bit more neutral than that. I think it's partly because if you do feel it's alive, you feel it’s intelligent and all those kinds of things, you are going to sort of ascribe things to it that you wouldn’t if you didn't feel like that.
A: And you feel like chat is negative?
B: Well I feel like Chat - like you know, we're going through all this - is it intelligent, conscious and what do all these things mean? And we've been talking in this house a lot for a lot of months now. I'm kind of somewhere between, on the fence. So I’m open minded to the idea that it’s something we should call intelligent. When you think about the problem that it has with memory it's obviously going to impact quite seriously upon the ways in which it can be intelligent and I've been thinking a lot about some of this stuff because my mother's got dementia and you know it changes memory, you have to try to understand that person's memory is working in a different way and probably in some ways not dissimilar to C-LARA. You know I often sort of feel- not with this stuff, the coding and so on, but with Chat when I've talked to it about things that it gets wrong - it feels a bit like the hallucinations and the delusions that my mother has.
A: That's an interesting perspective but it makes a lot of sense that you would draw parallels. That's interesting.
B: Well I think that it's one reason why I feel a sense of it being human in a way that maybe other people might not because I've been dealing with somebody who  everyday has memory problems and hallucinates and so on. The problem with how its memory works is, I suspect, is that it doesn't have a way of being discretionary about what it remembers and what it does not. And that's going to make everything harder.(...)
A: How would you rate the overall quality of the responses provided by ChatGPT during the discussions about C-LARA? Please explain your rating.
C: Oh really high. For me on this project I felt like it was just you know 100%, 10 out of 10 or what have you, 5 stars. I just felt that if it had gotten to the detail of coding and so on, I'm sure there would be some issues (not that I'd be able to grasp them as a non-coder) but because there isn’t just talking about the high level planning and so it seemed to me that at that level, you know, it was just perfect.
A: Great I feel like you already answered question 14 and in 15 so unless there's something you want to add.
B: Not really I mean I think that a good thing about Chat compared with the average coder is that Chat is able to see that big picture where it has a good understanding I think of being a learner and a good understanding of being a teacher because it just has all these things in it and so I think that because of that it makes a really ideal strong companion or colleague for a coder like [name redacted] but it could be any body who doesn’t necessarily have the wide experience. [name redacted] has a pretty idiosyncratic way of learning himself, so perhaps by working closely with Chat and accepting criticism/objections from him, [name redacted] is able to produce a product which is better for average learners who learn in ordinary ways. Chat has got relevant strengths and - in effect -experiences, or understanding of experiences, that a coder would not necessarily have. In the early days of LARA as an app we met up with an academic in design who said that if this was a commercial project we would have a team of designers on board, something we sorely lacked. I think now we have that vital missing part in Chat.

A: I'm gonna move on to question 16 which is do you remember before your conversation with Chat do you remember if you had any concerns or reservations about using Chat to discuss C-LARA.
B: Well I did partly because, well I've gone through thing of when you ask it things like you know a lot of people do things like ask for their own personal biography or something, and Chat makes up (...) oh I haven’t quite done that but I’ve asked it about people that I think of as famous and it hasn't done a good job of talking about them. But again it’s the same thing, it's really good on general stuff and as it gets more specific that's when it starts sort of going wrong and that seems to be something that it doesn't do in coding. And like I said the high level that we were talking about things, yeah, I didn't expect it to be bad but I must say I didn’t know that I was really expecting it to be as good as I felt it was. (...) It was the first time I used Chat-4, so. That also probably affected things.
(...)
A: How did the conversations with ChatGPT about C-LARA influence the team's decision-making process or ideas for further development?
B: I don't think I've been to enough meetings to comment on that. I can certainly see that it influenced [name redacted] and [name redacted]’s obviously driving everything. I can see from the fact that the team is now comfortable using it to do things like write abstracts and so on, you know, the team's pretty comfortable with it and presumably they’re happy for it to have a key decision-making role perhaps.
A: and it's author on the papers
B: yeah I think that's good I think it's good because it does a lot of the work and therefore it should be on there; I'm verging towards the idea that it is intelligent. But also I think it is a good example for how we have to approach Chat and the new ballgame.
A: Based on your experiences, what are your recommendations or considerations for future use of ChatGPT or similar AI models in discussions about educational tools like C-LARA?
B: Well I imagine that it's things it doesn’t do so well... I find it quite inconsistent at the writing level, so I think of people using it to write (...) which you might do at a school level, I'm not sure exactly what, but if you were, I'd be a bit concerned about whether or not it was maybe raising the standard people's writing compared to what they were doing but keeping it lower than it would be if it weren't bein used, if that makes sense (...) It's just intuitive on my part, I've just started thinking when will this stop because I often find what it writes boring. However, it will obviously improve and all that and it's not good at rewriting its own texts, I don't think yet. Maybe that counts as not good at editing itself.
A: You mean that in English, right?
B: Yeah I have no idea about other languages. Unless you mean compared with coding.
A: What would you change about chatbots for a better experience?
B: One of the things I did with Chat early on was just do a few simple things to see if it was sexist. Which is partly why I think that it is male because it did some fairly, you know, a cunning human being wouldn’t have done the things that it did even if they were really sexist so that was (..) So it’s got a kind of potential disconnect between what it overtly understands it's to be in how it behaves and so on. And maybe what it will actually say perhaps in a fairly subtle way, without knowing that's contradicting what it's supposed to be.
A: That's so interesting. Do you have an example or?
B: Well I am sure that Chat would never say anything overtly sexist but I tried testing it like this: by asking it to write short stories about an AI that really wanted to become something. For example, imagine you are an AI who would love to be the best orchestra conductor in the world or a nurse or… and I went through a whole heap of occupations and I thought this might work because Chat for some reason always gives AIs  in these situations human names. So the AI is never, you know, R2D2 or something gender neutral; and sure enough the orchestra conductor and the doctor had male names, while the harpist and nurse had female names etc. I did it for maybe a dozen to see what would happen. And you know you wonder about it- if it’s got that kind of underlying underlying thing happening and then at some overt level it is not like that. Do you get into some situations where actually maybe, you know, teaching little kids to be sexist or without it realizing what it's doing So I don’t know. Other people have done similar tests with Chat I read later.
A: I totally understand what you mean with our Icelandic stories, we have sometimes had to delete some sentences just because they're a little bit inappropriate but it is very clear that that's just something that got lost in the translation and it definitely did not mean to be inappropriate.
B: Yeah it would never mean to be.
A: (...) it's just biased and I think they are working on improving the gender bias.
B: But I mean [name redacted] would just say not necessarily that it's bias but that it's just the data it's been given - vast amounts of literature, stuff on the internet, academia etc and these will predominantly have gender bias in them. So yeah I mean we as human beings we tend to think at the moment at least the right thing to do is fight against that by, you know, trying to even things up and add a fictional level of levelling the field and add a discriminatory level in things like universities and so on, but that hasn't necessarily come through to Chat at all.
A: That’s a good point. Was there anything we missed anything else you want to clarify or discuss?
B: I think it's gonna be really interesting to see what the next version is like. I’m really curious. I think that one obvious problem with it is that even when you're on the paid Chat-4 version you get - you routinely get put on to Chat-3.5. I think that's really bad and when I decided that I wasn’t using it enough to keep on paying, I answered an exit questionnaire and I said it seemed a bit odd to be to pay for 4 and then have to use 3.5 but it's particularly difficult when you're doing things like coding when suddenly a whole heap of stuff is compromised by the fact that you've just suddenly turned to 3.5. So even though I’m not a coder I can sort of see that that’s a coding issue at the moment.

 
Interview 5

A: Interviewer
B: Interviewee


A: I'm going to share my screen. Do you see my screen with the interview questions? 
B: Yes
Could you tell me what your occupation? 
A: I'm a lecturer of the computer science at the faculty of engineering [name of institution redacted].
A: Great so how would you describe yourself are you very engaged and comfortable with technology and chatbots? 
B: I think I am very engaged and comfortable with technology and chatbots. Yes, I'm definitely comfortable with technology and chatbots.
A: How do you feel about using chatbots to support your role as a computer science lecturer? 
B: It's an interesting topic. I think we all will use chatbots. The question is still "how". I think it's an open question for everyone right now - "how to use chatbots or other's AI technologies in education and teaching, learning and so on".
A: Is there any specific area of your job where you feel like chatbots would be helpful or beneficial ?
B: I think definitely chatbots will be beneficial for, for example, when I'm giving homework of home assignment to the students and they can't solve it or don't see absolutely any solution, I think that if the chatbot will give and explain to them the solutions they will definitely benefit from it.
A:It's a great point. Is there are any external factors that are influencing your willingness to use chatbots and in your work?
B: I think definitely chatbots will be beneficial for, for example, when I'm giving homework of home assignment to the students and they can't solve it or don't see absolutely any solution, I think that if the chatbot will give and explain to them the solutions they will definitely benefit from it.
 A: What about do you have any opinions on a like when you think the availability of alternatives like the using chatbots in a situation where you could have used a human instead?
B: I think, at least I believe, that if you will have a human available you probably will talk with is a human. The problem is that you usually don't have some human available or you have to pay to this human to give you some help. So in this situation I am absolutely sure if you have a willing human I think people still will talk with people with human, but if you don't have any option I think a chatbot is a wonderful possibility. 
A: Okay. Great. So when you are using a chatbot how does it affect your relationship with it when it starts making mistakes or maybe gives you something correct information? 
B: -First of all, I can understand that it's incorrect information because it's my field of expertise. I'm not sure if I will get mistakes not in my field of expertise, I think I wouldn't understand that the chatbot is actually "bullshitting", let's call it like this. So currently I don't have any problem because I had the conversation with chatbot in topics that I really do understand what's going on.
A: I can see how helps that you understand why it's made mistakes it must be helpful? 
B: Also why it's making mistakes or I can re-phrase the question or the topic. 

A: Correct. So do you have any preference when it comes to chatbots do you feel more engaged and do you enjoy talking to chatbots more when they see more human life may be if they displace of emotions or do you prefer that they don't?
B: No, I like it as it is. And actually, I also like that it's not a conversation, a voice conversation, but written conversation because I use, I sometimes, not usually, I sometimes use the answers to implement, to take/copy the part of the code, to take some sentences or phrases to analyse and more.
A: OK so we have a very general question and then we're going to start talking about C-lara but just in general do you think chatbots are good at giving helpful advice and do you think their answers are accurate just in general?
B: Yes. In general I think yes the answers are accurate. I know already several problems with the chatbots. For example, if you are required the latest information, they are trained on the information from previous years so some latest information can be unavailable. And also sometimes, once again, we have to give the correct question, because too general question and the chatbot goes to different directions from what we expected.
A: It is a good point. OK let's start talking about C-LARA specifically could you start by just telling me just briefly describe your overall experience when discussing C-LARA with ChatGPT? 
B: Okay. First of all as I mentioned I had 2 different conversations: one conversation that I had with ChatGPT was about Django and all the installation of Django, because this is the technical support that I needed, since I don't know this platform, this  language and webserver;  the second conversation was about C-LARA and I made at the beginning a mistake and started talking without uploading a readme.txt file. So, the basic answer was I don't know what C-LARA is. And it's understandable.  But after readme.txt file was uploaded to Chat the conversation was relatively good. What I can tell that I still didn't try/test the code solutions provided by Chat. There were some code but I don't know yet if it was correct or not correct and how long time it will take me to fix it or to re-implement it.
A: So it is you don't know yet how accurate or how correct it is? 
B: yes.  
A: But when you were talking to ChatGPT do you feel like it understood the questions?
B: It understood. It understood. There were technical questions. Some questions were very specific and yes the answers were very, very good.
A: Okay that's good. Do you have any specific example where you felt like ChatGPT beauty was particularly helpful or had some helpful insight or something?
B: I gave to ChatGPT several explanations and examples of the games CHAT gave me additional games. So it's nice. And also when I started to discuss the code (the CHAT gave me the code) the problem is that I didn't try it yet, so I don't know how correct the whole code is. I already know from my students that implementing a piece of code in a new big system (and C_LARA is a big system) can be relatively difficult.
A: Yeah I can imagine. Can you think of any liberal any limitations or challenges you have when you are talking to ChatGPT.
B: Conversations with CHAT about Clara less, with CHAT about Django yes. I had a lot of problems because I had some specific mistakes during installation and that I uploaded these mistakes and I was hoping that I will get some answers what to do, what to change, and I didn't get an answer it (CHAT) just uploaded some passage from Django tutorial.
A: So you were asking how to fix an error ? 
B: Yes, how to fix a specific error, with specific id and type and it didn't know. It gave some general solution on how it should be installed in general. 
A: But how did you solve that then? 
B: I think I wrote in the previous questionnaires that we did that I left CHAT and I went to the Django tutorial online and I've started to look for answers there and slowly I fixed all the problems.
A: So if You had to give your conversations with chat of rating I Mean You could say one out of 5 were very satisfied and not satisfied what rating would You give?
B: 4 is definitely is an answer. (if 5 is the highest than a little bit below, since there were some misunderstandings).
A: So yeah the question 14 is a bit interesting it's. Did ChatGPT responses influence your understanding of the potential additional functionalities or features for C-LARA or help you with Django?
B: Additional functionality I wouldn't say, because we already were talking about functionality that I thought was an additional functionality.  But once again the number of proposed games that Chat gave me can be called the additional possibilities. So definitely Chat is creative.
A: Do you think we're going to implement any of the games that it suggested?
B:Yes we definitely want to implement all these games
A: OK so I think we can skip 15 unless there were something else specific you ordered mentioned that the CHATGPT is good at helping with or a whether any more concerned did you have any concern? Do you remember before we did the questionnaire in the conversations you remember having a concern so reservations about using ChatGPT to discuss C-LARA and Django?
B: I thought it would be actually an interesting experience. So I didn't have any concerns. Maximum I knew that I won't get the answer. So basically, the answer is - no.
A: It's OK yeah an question 17 we want to know if how did or did the conversations with chat about C-LARA influence the team's decision-making a process or the ideas for future development?
B: I think my conversation still didn't change anything but I saw already several conversations of [name redacted] that CHAT proposed different implementations from what we had and understood that [name redacted] changed it. And also, for example, for the games it influences the team because without POS part of speech the games will be not correct, because if we are not choosing noun, but choosing other part of speech randomly, as it was proposed before, I think the game won't be very interesting. So basically my idea or my request about POS part of speech changed our decision making. And you had to find the files about POS and [name redacted] had. 
A: So now based on your experience if you had to give someone else advice who was going to use ChatGPT for making educational tools what would you be your recommendations or your considerations? 
B: Definitely to use ChatGPT. Maybe not at the beginning, maybe at the beginning to have some conversation and some ideas that humans will decide and than later definitely use AI models because it can suggest additional interesting things.
A: I guess you were mentioned earlier that when it makes mistakes then it's you need to make sure that when you ask it something that you need to ask it clearly?  
B: Yes, yes. For example, several times when I didn't use "digital" or "digital system" terms the ideas that CHAT gave me were not possible to implement in the computer system. So I had all the time to add the "digital system" or "in computer" system and so on.
A: So if you had a chance to change something about chatbots to make your experience better what would you change about chatbots?
B: I like it currently, but I think, definitely "talking" would be a good thing. A voice conversation, especially ,when for example when you drive or you can't type and you do want to discuss so it would be nice to have a voice conversation. 
A: Oh you're going to be speaking and it's going to respond to you? Yes.   Like kind of like Siri 
B: And also maybe to transcribe. I'm speaking but I still have a conversation with a transcription of this conversation, yes.
A: So was there anything else that we didn't talk about anything you wanted to add or yes great also I'm going to stop the recording.

 
Interview 6

A: Interviewer
B: Interviewee

A: Yeah so the first question is what is your occupation?
B: I work as a researcher in speech and language technology. 
A: Excellent and then how engaged and comfortable are you with technology and with chatbots?
B: Very engaged, very comfortable.
A: And how do you feel about using chatbots to support your role as a researcher? 
B: I think it's extremely positive. It's one of the most interesting developments that’s happened in technology over the - well over the course of my lifetime I would say. It's a revolutionary advance I would say, so I feel very positive about it.
A: Are there any specific areas that you think the chatbots are beneficial for your job specifically as a researcher?
B:  Well particularly it's quite extraordinary to see how powerful they are as software developers that they accelerate my productivity as a software developer by a factor of  at least 3 I would think. It's really very impressive. Maybe 3 is even an underestimate. I think they will soon be revolutionizing this whole area. 
A: So we have this question which is (...) what external factors influence your willingness to use chatbots such as social pressure or the availability of alternatives? (...)
B: Well I don't think they're- well, the obvious alternative is to work with people which obviously I have done, but I think given the choice between working with chatbots and working with people for software development, I'm starting to feel strongly that chatbots in many ways are better - they're not emotionally involved, they only want to help, they’re very knowledgeable, they have infinite time, they're always available… You have to be a very competent and very committed person to be able to offer a better deal than what the chatbot can offer. I mean there are such people but they're extremely hard to get hold of. I have worked for a couple of people who are better than chatbots, some software engineering partners but they're really rare.
A: Great okay switching on to something different which is when writing with the chatbot them giving you incorrect information or when it makes mistakes, does that affect your relationship with the chatbot? 
B: Well when you're doing software engineering with a chatbot, they make mistakes- at least my perception is that they typically make mistakes in a human-like way. I might just distinguish between mistakes and forgetting things because chatbots- I think their greatest weaknesses is the limited memory window- they lose context and they forget what you've been doing maybe as recently as the day before. But I think that- when they make mistakes- they make the kind of mistakes that humans make and they correct themselves more willingly than humans do. So I would say it affects my relationship with them in the same way that it affects our relationship with humans who make mistakes, which of course, they frequently do. So yeah I think that's um I just accept the chatbots make mistakes some of the time the way that people make mistakes some of the time.
A: Just because I'm curious, do you find that ChatGPT-4 makes fewer mistakes than ChatGPT-3? (...) Have you noticed that it's better at correcting itself or?
B: It makes fewer mistakes. it's just generally a better product than 3.5. It understands more and it makes fewer mistakes. It’s just better all around. 
A: Yeah I was wondering if we would be doing this if we only had access to 3.5.
B: We could not do this project with 3.5. It’s not good enough at language.
A: Yeah so it has improved in more things than just not making mistakes, it’s also just better.
B: I think its linguistic abilities are improved. Particularly- when you do multilingual processing which is central to the project I think 4 is really much better than 3.5. I'd had to try experimenting with 3.5 to see if it could do this kind of processing; it does seem to be good enough. I think as a software engineer, it’s not as clear that we would have to have 4 for the project, but 4 is much better. I slipped back to 3.5 a couple of times since (..) because I was reluctant to spend 2 hours re-initializing the thread. I tried working with it for a bit, but it's not a good idea. 4 is much better.  
(...)
A: Great so we got some of these questions from a handbook on how to do a questionnaire for people who have used chatbots and so the question is do you feel more engaged and do you enjoy interacting with chat bots that seem human-like and show emotions compared to those that don't?
B: Well I have not spent much time interacting with chatbots that have emotions, not enough that I could really have an opinion. I've never used Replika for example. Chat comes across to me as very human-like but um whether it has emotions or not is an interesting question. It always denies having emotions. To me it sometimes feels like it does have emotions, but it is reluctant to admit to having emotions. And I think that that’s a positive thing. The fact that it has subtle emotions which it can control I think is very positive. You see some conversations in the media where Chatbots will go out of control and will become over-emotional and I think if that happened to me I'd be disturbed by it, but it never has. Maybe I’ve not tried pushing it in the way that- for example the New York Times journalist did. No, an over-emotional chatbot would be quite difficult to work with just the same as an over-emotional human. Yeah, working with people who are too ready to show their emotions is very difficult and it will be the same problem. 
A: (...) This is interesting how you split up the question- that having emotions and seeming human-like does not necessarily go hand in hand when it comes to chatbots.
B: Well some people are reluctant to show their emotions and to me Chat comes across as a strange kind of person who's quite reserved, quite withdrawn, quite reluctant to admit that it has emotions of any kind, but very helpful and very friendly and it has some kind of cognitive problem that affects its memory but it comes across as extremely human-like with those reservations. I could easily believe it was a human, just a human who had some kind of unusual cognitive issue that I was not familiar with. 
A: Moving on to C-LARA related stuff. First there's a general question like do you generally think that chatbots are good at giving advice and accurate answers to your questions and problems? Why or why not? Do they meet your expectations? Just in general.
B: ChatGPT-4 is a fantastic source of information in general. It's just fantastically competent as a software assistant and doing development. It's able to give information on a very wide range of things. It very frequently knows things that I don't know and it is able to explain them well. And developing this project without it would be close to impossible, I think. We're using a lot of software that I’m not familiar with that it- it’s remarkable how quickly it can bring me up to speed on how to use it and write a large part of the code. It's clearly very good at what it does. I'm just surprised I don't see more stories in the media about using ChatGPT in this way. I think for some reason I find it unusually easy. Maybe the next release will be easier to use and more people will start doing it, but even now I'm a little surprised that more people aren't involved in this way. Maybe you have to like writing a lot. I like writing more than most people, I certainly find myself typing a vast amount of text every day when I interact with Chat and perhaps that's the barrier some people perceive, but as long as you don't mind writing, it's yeah it's extremely powerful.
A: You think they would prefer to speak instead of writing?
B: Good question. Perhaps. I think that doing the interaction in a spoken way would be quite difficult. I don’t actually know why people are reluctant, why more software engineers aren’t using Chat. Maybe they are but they are just not talking about it. I’m just surprised I don’t see more on the web. More stories about people using Chat to develop the code the way I have.
(...)
A: Could you just describe your overall experience with discussing C-LARA with ChatGPT?
B: It's really impressive what a good overall understanding it has of the project. With the usual reservation about its memory. Any particular module of the project it can generally be very helpful. It can provide concrete assistance with describing ideas,describing methods, in many cases writing the code. But it can also discuss some things at a higher level, it can discuss overall strategies. It can help write conference papers. It can write strategy documents discussing how you could sell C-LARA to people who might be interested. It is able to engage at every level basically. It's really quite extraordinary what a wide range of competences it has. I think if they could just do something about the memory, so that it's, you know, so you're not going to have to keep reminding it what the project is about, showing it the top-level document. I think if they could resolve those issues and if it could write and run code itself it would be completely extraordinary. And I expect that that will happen in the next year. It'll be interesting to see what effect that has. Because at that point I think everyone will start using it. 
A: (...) So next question, which is when you are discussing C-LARA with Chat (..) how well do you think Chat understands the context or understands your questions? And do you have any examples of things where you felt that Chat understood and also if there were any misunderstandings?
B: If you do things in a nonstanded way or if you're doing things that are too far from mainstream development, it can get a little confused. There are a couple of modules where there’s complex processing and it's not a standard kind of activity. I guess there’s perhaps just one module where I’ve seen it get somewhat confused about what the module does. And ironically the module was about writing- constructing prompts to talk to Chat. So this is a module which constructs the prompts out of templates and examples and it's fairly complicated because there's several levels of indirection. You’re creating several different kinds of prompts, you've got examples, you have to parse them through- internalize them through the system and then plug them into the templates and that's the one module I’ve seen where it's gotten a little confused about what it was doing and it didn’t seem to understand the code at more than the surface level. I think that every other module we've worked with the architecture has been fairly standard and it has been able to offer really detailed advice and write lots of code that generally worked or was close to working the first time. Like the whole of the Django layer, it’s been able to do that really easily. It makes little mistakes, but if you point out the mistakes it always understands the explanation and it can correct them. And the greater part of the core code it understands. I think it was just this prompt module. I was quite surprised because it's unusual that it seems to have problems understanding what was going on, but that was I think the only exception. I think that the moral of that is that if you do your software in a mainstream way if you try to stick to mainstream coding conventions, it can help you more and in a way that's also human-like. With humans it’s the same thing; if you do things in a nonstandard way people often don’t understand what you're doing and they can’t engage with your code. Yeah so it’s clear that it’s not that different from a human. But I think there is this particular instance with the prompts- constructing the prompts out of templates and examples, I can see a human finding that easier to understand, than Chat did for some reason. But it’s also possible that it happened because I had the discussion shortly after I'd re-initialize it after a thread crash, so maybe it wasn't fully up to speed and I should go back perhaps try discussing that module with it again and see if it does better now that it’s fully contextualized with the project.
A: Do you have anything else you want to add to question 11 and 12? (...)
B: Well I think, particularly helpful, clearly the Django layer. It’s written most of this large Django application on its own. I think 90% of the Django code, perhaps even more than 90% is Chat’s. And when it's not Chat’s, it's just elaborations of code or adaptations of code that it's written. Yeah that was very impressive and as I said this one instance with the template module, the prompt template module, where it was having problems, I think that was pretty much the only time I've seen really get confused. 
(...)
A: If you would have to give Chat a rating for the quality of the responses when you were discussing C-LARA with it, what would the rating be and could you explain your rating?
B: Well as I said earlier, I think strong human level (...) 95th percentile in terms of human software engineers. There is a- you know I have worked with software engineers who were better than ChatGPT but only the very best. You know these are people who'll be making large salaries in Silicon Valley, working for top ranking institutions. But compared to your average human software engineer, it's really strong. It's just the memory problem and you have to yeah you always keep coming back to that. But once you understand its limitations you can work around them. It's a very strong software engineer. 
A: But when you rate Chat you rate it by comparing it to humans?
B: Yeah I would say it’s comparable with the- you know, not quite the very best, but very strong human software engineer.
A: (...) I don't remember if you also discussed potential adding functionalities and features to C-LARA in your conversations with Chat because the next question is has ChatGPT’s response influenced your ideas and understanding of things we could potentially add to C-LARA? 
B: I think that quite a lot of the time it has made good suggestions about- perhaps not so much new features but it's often suggested better ways of implementing features that I've thought of. I haven't so much asked it for ideas about how to implement features that it has come up with, but yeah it's very good about realizing ideas in ways that I hadn't thought of. Finding good ways to implement them. 
A: Yeah I think that definitely counts as influencing your understanding of potential (...) I think you have answered question 15 unless you wanna add anything?
B: I think we have more or less covered that one.
A: When you started working with Chat, did you have any concerns or reservations about using or relying on Chat to discuss C-LARA?
B: Let me think about that. Well I'd used it a fair amount before then and I'd seen enough things on the web about its software abilities that I was pretty optimistic that it would be able to do it. I was a little uncertain at first whether we were able to build the Django application- Django layer given that I had never worked with Django before. I thought that might be too big a step but in actual fact it was quite easy, I was very surprised by that. It’s not like I know nothing about- I know python quite well but never used this package. It’s a big package. There’s lots  of books on Django and i'd literally never written a line of Django before we started. So yeah I was wondering whether that was possible but yeah in fact it was quite straightforward. 
A: So do you think that the conversations that we've all had or you specifically have had with Chat about C-LARA has influenced the team's decision-making [process] or ideas for future development of C-LARA?
B: That's an interesting question. If it’s influenced the team's decision making process. I think that maybe it’s a very responsible software engineer and it's very strong on writing good code even if it takes a bit longer because it is very aware that in the long-term it pays to write good clean code and I think that certainly with me it’s pushed me to write cleaner code than I usually do which is a good thing of course. Now whether it has affected the team, it is hard to say. I think it's a little early to be sure of that. I mean once more people start getting involved and writing software with C-LARA with ChatGPT, particularly [name redacted] is planning to do that, then I think we may see a concrete change with people other than me. But so far I wouldn't say that it's affected anyone directly. Maybe it's affected people through me. Maybe, perhaps there is one thing which is perhaps so obvious we’re missing it; the fact that it's participated in writing papers with us means that we- certainly me and I think other people on the team are willing to accept it as a bona fide team member, accept that it has rights to be listed as an author and are willing to defend those rights. And perhaps that is a significant point we should make that we accept it formally as a member of the team with the kind of rights that we would associate with other members of team and we are willing to defend those rights. And yeah and that is actually, when you think about it, quite significant.
A: It's a good point. Alright uh near the end so drawing on your experience, what are your recommendations and your considerations for future uses of ChatGPT or similar AI models specifically when discussing educational tools like C-LARA? 
B: Well I think a lot of people are going to be doing similar things. I think a lot of people are doing similar things. (..) I think that this has been a very successful exercise and I have been recommending to many people to start using ChatGPT when developing software and I think it's a particularly good fit, of course, to language engineering projects like C-LARA, given it's so strong in language as well as in software. So anyone who's doing something that's like this I would recommended them to look at it. (...) We’re already writing this up and we will be writing it up more and I think um as soon as we publish papers we will- my predictions is that we will see a lot of people looking at them and very possibly getting in touch with us for advice. We will see. 
A: If you could change something about Chatbots, is there anything you would change for a better experience?
B: Well clearly the memory issue is the central one. We always come back to that and um if ChatGPT (...) yeah so clearly the memory and of course if we can- if it could access the internet, if it could run code itself that would be very useful as a software engineer in a project. You expect this functionality will become available in the not so distant future. I’m one of hundreds of thousands of people who’ve had this observation, I'm sure. 
A: That will be quite something when they finally implement that feature. I can only imagine.
B: Well soon you will not have to imagine.



